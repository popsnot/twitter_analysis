{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0O_fzYiSbZcM",
        "outputId": "7ecff81a-38dd-4f5a-85ed-d9dad7f5da60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: PYTHONHASHSEED=3\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "%env PYTHONHASHSEED 3\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!pip install -q pyspark\n",
        "\n",
        "from math import sqrt\n",
        "import pyspark\n",
        "from pyspark.sql import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rb7FRgdabKm8",
        "outputId": "261af024-1a19-4b52-d098-117a8cfa9b17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from pyspark import SparkContext, SparkConf\n",
        "import os\n",
        "\n",
        "directory = \"/content/drive/My Drive/twitter\" #The directory in my Google Drive containing our files.\n",
        "\n",
        "spark = SparkSession.builder.master(\"local[*]\").appName('Twitter Analysis').config(\n",
        "    \"spark.executor.memory\", \"1g\").config(\"spark.ui.port\", \"4050\"\n",
        "        ).getOrCreate()\n",
        "sc = spark.sparkContext\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "raw_edges = sc.textFile('/content/drive/My Drive/twitter_analysis/edges_rdd.txt') #This is our pre-processed file containing all our twitter graph edges.\n",
        "\n",
        "files = [a_file for a_file in os.listdir(directory) if a_file.endswith(\".edges\")] #Gets a list of all files in our directory specified above.\n",
        "ego_users = [int(os.path.splitext(file)[0]) for file in files] #Generates list of all ego users, with which to filter the PageRank output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6k-Okykpj0zi"
      },
      "outputs": [],
      "source": [
        "def get_sources_and_destinations(raw_edges_file):\n",
        "  \"\"\" Modified version of 2(a). from lab 4, reads in text file and converts it into an RDD of format: (source, [destinations])\"\"\"\n",
        "  edges_rdd = raw_edges_file.map(lambda x: (int(x.split(',')[0].split('r=')[1].strip(\"'\")), int(x.split(',')[1].split('d=')[1].split(')')[0].strip(\"'\"))))\n",
        "  #edges_rdd = edges.map(lambda x: tuple(x.split(',')))\n",
        "  #edges_rdd = edges_rdd.map(lambda x: x[0].split(\"'\")[1]).map(lambda x: (int(x.split()[0]), int(x.split()[1]))) #Formats our RDD to (source, destination) pairs of graph nodes\n",
        "  graph_rdd = edges_rdd.groupByKey().map(lambda x: (x[0], list(x[1])))\n",
        "  return graph_rdd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Pg5qV1JX1Ht9"
      },
      "outputs": [],
      "source": [
        "def get_col_trans_matrix(graph_rdd):\n",
        "  def get_length(destinations):\n",
        "    destinations = set(destinations)\n",
        "    output = {}\n",
        "    for item in destinations:\n",
        "      output[item] = 1/len(destinations)\n",
        "    return output\n",
        "  col_matrix = graph_rdd.map(lambda x: (x[0], get_length(x[1])))\n",
        "  return col_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "UXzSIqKLppJh"
      },
      "outputs": [],
      "source": [
        "def col_to_row_matrix(col_trans_matrix):\n",
        "    row_matrix = col_trans_matrix.flatMap(lambda column: ((row, (column[0], column[1][row])) for row in column[1])).groupByKey().sortByKey()\n",
        "    return row_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "BMDjx_iyq36K"
      },
      "outputs": [],
      "source": [
        "def row_multiply(row, R):\n",
        "    result = 0\n",
        "    for column, value in row:\n",
        "      if column in R:\n",
        "        result += value * R[column]\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JeuDszby8Pms",
        "outputId": "b10138d3-7804-4914-edda-4182c927b64f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PythonRDD[16] at RDD at PythonRDD.scala:53"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "def produce_main_input(file):\n",
        "  return col_to_row_matrix(get_col_trans_matrix(get_sources_and_destinations(file)))\n",
        "input = produce_main_input(raw_edges)\n",
        "input.persist() #Caches to make future calls to the RDD faster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "WcORBMhqeMFg"
      },
      "outputs": [],
      "source": [
        "def page_rank_main(input, iterations=90, convergence_threshold=0.001):\n",
        "    graph_rows = input\n",
        "    N = graph_rows.count()\n",
        "    damping_factor = 0.85\n",
        "    R = graph_rows.map(lambda x: (x[0], 1/N)).collectAsMap()\n",
        "    previous_R = R.copy()\n",
        "    for t in range(iterations):\n",
        "        vecR = sc.broadcast(R)\n",
        "        row_results = graph_rows.map(lambda kv: (kv[0], row_multiply(kv[1], vecR.value)))\n",
        "        R = row_results.reduceByKey(lambda a, b: damping_factor*a + (1 - damping_factor)/N + b).collectAsMap()\n",
        "        # Check if values have converged\n",
        "        delta = sum(abs(R[i] - previous_R[i]) for i in R.keys())\n",
        "        if delta < convergence_threshold:\n",
        "            break # Stops the loop, preventing unnecessary iterations\n",
        "        previous_R = R.copy()\n",
        "    # Sort by rank and return the top 10 results\n",
        "    top_results = row_results\n",
        "    graph_rows.unpersist()\n",
        "    return top_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "iys_z18S-bsl"
      },
      "outputs": [],
      "source": [
        "output = page_rank_main(input).filter(lambda x: x[0] in ego_users).sortBy(lambda x: -x[1])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "influential_users = output.take(20)"
      ],
      "metadata": {
        "id": "w7kGbJqbBpPw"
      },
      "execution_count": 10,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}